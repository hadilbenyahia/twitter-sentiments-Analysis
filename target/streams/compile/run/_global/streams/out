[0m[[0m[31merror[0m] [0m[0mjava.lang.IllegalArgumentException: requirement failed: The number of columns doesn't match.[0m
[0m[[0m[31merror[0m] [0m[0mOld column names (1): value[0m
[0m[[0m[31merror[0m] [0m[0mNew column names (2): tweet, entity[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.Predef$.require(Predef.scala:337)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.Dataset.toDF(Dataset.scala:504)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.sql.DatasetHolder.toDF(DatasetHolder.scala:44)[0m
[0m[[0m[31merror[0m] [0m[0m	at TwitterStreamSimulator$.$anonfun$main$3(Main.scala:70)[0m
[0m[[0m[31merror[0m] [0m[0m	at TwitterStreamSimulator$.$anonfun$main$3$adapted(Main.scala:65)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2(DStream.scala:629)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.dstream.DStream.$anonfun$foreachRDD$2$adapted(DStream.scala:629)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.Try$.apply(Try.scala:217)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)[0m
[0m[[0m[31merror[0m] [0m[0m	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)[0m
[0m[[0m[31merror[0m] [0m[0m	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)[0m
[0m[[0m[31merror[0m] [0m[0m	at java.base/java.lang.Thread.run(Thread.java:829)[0m
[0m[[0m[31merror[0m] [0m[0m(Compile / [31mrun[0m) java.lang.IllegalArgumentException: requirement failed: The number of columns doesn't match.[0m
[0m[[0m[31merror[0m] [0m[0mOld column names (1): value[0m
[0m[[0m[31merror[0m] [0m[0mNew column names (2): tweet, entity[0m
